# Essay-Marking-Assistant
.

Abstract
Automated Essay Scoring (AES) or Automated Essay Grading (AEG) refers
to a challenging Natural Language Processing task (NLP) which involves evaluation of descriptive answer scripts to provide a legitimate human equivalent
result. Deep learning method is significantly exploited by most of the researchers
to encounter the task with more than a thousand dataset. However, collection
and collation of dataset for every domain could be challenging. This is because
during collection of these dataset, a human evaluator is required to evaluate
each answer, which could be strenuous. The other way of tackling AES, involves information extraction, taxonomy, understanding coherence, etc. but
despite collecting all these features to tackle the AES task, it has still not been
able to yield a human equivalent result.
The proposed frameworks aim to develop an assistant for a human evaluator.
It assists human evaluators by highlighting using different fonts and colors on
keywords and sentences identified by NLP and deep learning. The motive of
using highlights and different fonts is to ease the answer evaluation process for
the evaluator. In addition, the proposed framework pipeline exploits current
state-of-art methodologies to perform AES with minimal dataset. Therefore,
Essay Marking Assistant (EMA) is an assistant which not only eases the process
of evaluating descriptive answers for a human evaluator, but also performs AES
to provide a reasonable estimate. However, this requires human effort to confirm
and finalise the result.
Keywords: Automated Essay Scoring, Natural Language Processing, Essay
Marking Assistant, coherence, Information extraction.
